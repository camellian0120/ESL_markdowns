## 5.6. ノンパラメトリックロジスティック回帰
単一の定量的入力$X$に対するロジスティック回帰を考える。\
ロジスティック関数$f(x)$による当てはめで、滑らかな条件付き確率$Pr(Y = 1| x)$を求めることができる。
$$\begin{align}\log \frac{Pr(Y = 1| X = x)}{Pr(Y = 0| X = x)} &= f(x) \tag{5.28} \\
Pr(Y = 1|X=x) &= \frac{e^{f(x)}}{1+e^{f(x)}} \tag{5.29} \end{align}$$

また、罰則付き対数尤度基準$l(f; \lambda)$を、次式のように構成する。\
ただし、$p(x) = Pr(Y = 1| x)$である。
$$\begin{align}
l(f; \lambda) &= \sum^N_{i=1} [y_i \log p(x_i) + (1 - y_i)\log (1 - p(x_i))] - \frac{1}{2} \lambda \int \{f'' (x) \}^2 dt \\
&= \sum^N_{i=1} [y_i f(x_i) + \log (1 + e^{f(x_i)})] - \frac{1}{2} \lambda \int \{f'' (x) \}^2 dt 
\end{align} \tag{5.30}$$
この時、最適な$f$は$x$に接点を持つ自然スプラインなので、$f(x) = \sum^N_{j=1} N_j (x) \theta_j$である。\
そして、1次と2次の導関数は以下のように表される。\
ただし、$p$は$p(x_i)$を要素として持つ$N$次元ベクトル、$W$は重み$p(x_i)(1 - p(x_i))$の対角行列である。
$$\begin{align}
\frac{\vartheta l(\theta)}{\vartheta \theta} &= N^T (y - p) - \lambda \Omega \theta \tag{5.31} \\
\frac{\vartheta ^2 l(\theta)}{\vartheta \theta \vartheta \theta^T} &= -N^T WN - \lambda\Omega\tag{5.32}
\end{align}$$
(5.31)は$\theta$について非線形であるため、反復的な計算が必要である。\
ニュートン=ラフソン アルゴリズムを使って、$theta$の更新式を表せる。\
ただし、作業応答変数$z$は重み付き平滑化スプラインへの当てはめ、$S_\lambda$は回帰演算子である。
$$\begin{align}
\theta^{new} &= (N^T WN + \lambda \Omega)^{-1} NW (N \theta^{old} + W^{-1} (y-p)) \\
&= (N^T WN + \lambda \Omega)^{-1} NWz
\end{align} \tag{5.33}$$
$$\begin{align}
f^{new} &= N(N^T WN + \lambda \Omega)^{-1} N^T W (f^{old} + W^{-1} (y-p)) \\
&= S_{\lambda, w} z
\end{align} \tag{5.34}$$

ニュートン=ラフソン アルゴリズム ... 非線形方程式$f(x) = 0$を数値的に解く方法
> https://note.com/kiyo_ai_note/n/n197ec395055a

## 5.7. 多次元スプライン
スプラインを多次元で扱うために、基底を追加する。
1. 座標$X_1$ の関数を表す$M_1$個の基底$h_1j(X_j)$ 　 $(j = 1, ..., M_1)$
2. 座標$X_2$ の関数を表す$M_2$個の基底$h_2k(X_k)$ 　 $(k = 1, ..., M_2)$

これらによって定義される$M_1 \times M_2$次元の**テンソル積基底**を導入する。\
これは、2次関数を表現するのに使える。
$$g_{jk}(X) = h_{1j}(X_1) h_{2k}(X_2) 　 (j = 1, ..., M_1) (k = 1, ..., M_2)$$

多次元スプラインでも**Bスプライン**を用いたテンソル積基底によるスプラインを示せる。\
係数は最小2乗法で求めており、MARSに近い挙動を取る。
しかし、次元数が増えるとテンソル積基底は指数関数的に増え、次元の呪いが生じてしまう。

また、ロジスティック回帰による当てはめでも、テンソル積基底によるスプラインを示せる。\
決定境界において**柔軟性**があるが、その他の部分では、**誤分類**してしまいやすい。

一般化平滑化スプラインも高次源に一般化できる。
$x_i \in R^d$である組$y_i, x_i$が与えられた時、$d$次元回帰関数$f(x)$を求める。
$$\underset{f}{min} \sum^N_{i_1} \{ y_i - f(x_i) \}^2 + \lambda J[f] \tag{5.37}$$
$J$は関数$f$を安定させるための適切な罰則関数である。
$$ \tag{5.38}$$

前述の最適化は、**薄板スプライン (Thin-plate Spline)** の名前で知られ、以下の特徴がある。
1. 滑らかな2次元の表面が得られる。
2. 式(5.37)の$\lambda$に関して、以下の規則がある。
 2.1. $\lambda \rightarrow 0$の時、解は補完関数に近づく。
 2.2. $\lambda \rightarrow \infty$の時、解は最小2乗平面に近づく。
 2.3. その他の$\lambda$に関しては、 係数が一般化リッジ回帰で表される、基底関数の線型展開として表される。
 ただし、**動径基底関数(radial basis function)** $h_j(x) = \| x - x_j \|^2 \log \| x - x_j \|$
 $$f(x) = \beta_0 + \beta^T x + \sum^N_{j=1} \alpha_j h_j(x)$$

より一般的で**適切な$J$** を選べば、薄板スプラインは任意の次元$d$へと**一般化**できる。\
しかし、**計算量は$O(N^3)$と膨大**になる。\
$\rightarrow$ 実用上では、領域を覆う接点の講師を用いれば基本問題ない。\
 　 $K$接点$(K < N)$を元にすると計算量は$O(NK^2+K^3)$まで減らせる。

また、$f \in R^d$は任意の数の基底関数の集合による展開として表現できる。\
そのため、式(5.38)のように**正則化**が可能であり、複雑さを調整できる。

加法的スプラインモデルは、多次元スプラインを制限したクラスである。
座標$X_d$ の関数$f_d$が存在し、以下の式が成り立つ。
$$f(X) = \alpha + \sum^d_{j=1} f_j (X_j)$$
また、それぞれの$f_j$が1変量スプラインであることを保証する罰則$J[f]$が存在し、以下の通りである。
$$\begin{align}
J[f] &= J (f_1 + f_2 + ... + f_d)
&= \sum^d_{j=1} \int f_j'' (t_j)^2 dt_j
\end{align} \tag{5.40}$$

この際、各要素は所望の次元を持つスプラインであり、多数の選択の余地がある。
1. 相互作用の最大次数
2. どの項を含むべきか
3. その表現を用いるべきか
 3.1. 比較的少数の座標ごとの基底関数と、相互作用のためのテンソル積
 3.2. 全規定を用いた展開に、各項への適切な正則化を加えたもの
